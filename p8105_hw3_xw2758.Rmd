---
title: "p8105_hw3_xw2758"
author: "Xinyi Wang"
date: "10/10/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	fig.asp = 0.6,
	fig.width = 6,
	out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```

Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```

Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```


## Problem 2

### Fisrt, I will load, tidy, and otherwise wrangle the data.

```{r echo=TRUE}
acc_df = acc_df = read_csv("~/R_columbia/p8105/p8105_hw3_xw2758/data/accel_data.csv") %>% 
 janitor::clean_names() %>% 
 pivot_longer(
  activity_1:activity_1440,
  names_to = "minute",
  names_prefix = "activity.",
  values_to = "activity_counts"
 ) %>% 
 mutate(
  weekday_vs_weekend = case_when(
   day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "weekday",
   day  %in% c("Saturday","Sunday") ~ "weekend"
  )
 ) %>% 
  mutate(
    week = as.factor(week),
    day_id = as.factor(day_id), 
    day = as.factor(day),
    minute = as.numeric(minute),
    activity_counts = as.numeric(activity_counts),
    weekday_vs_weekend = as.factor(weekday_vs_weekend)
  )  %>% 
 mutate(day = forcats::fct_relevel(day,
                                   c("Monday","Tuesday","Wednesday","Thursday","Friday", "Saturday","Sunday"))
         )
```

acc_df dataset has `r nrow(acc_df)` observations and `r ncol(acc_df)`variables, including `r names(acc_df)` .

### Create a total activity variable for each day, and create a table showing these totals.

```{r echo=TRUE}
acc_df %>% 
 group_by(week,day) %>% 
  summarise(total_activity = sum(activity_counts)) %>% 
  pivot_wider(
    names_from = "day", 
    values_from = "total_activity") %>% 
 knitr::kable()
```

The acticivity counts are quite steady without too much change. However, the Saturday and Sunday in week 4&5 are quite low.

### Make a single-panel plot and describe 

```{r}
acc_df %>% 
  group_by(day_id, day, week) %>% 
  ggplot(aes(x = minute, y = activity_counts, color = day, group = day_id)) + 
  geom_point(alpha = 0.01) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  geom_smooth(se = F, method = 'loess') + 
  labs(title = "Activity of 63 yrs-old man plot",
       x = "Time(hour)",
       y = "activity count",
       caption = "24-hour activity acceleremoter data of 63 year-old male with BMI 25") + 
  scale_x_continuous(
    breaks = c(seq(120,1440,120)), 
    labels = c("2h", "4h", "6h", "8h", "10h", "12h","14h", "16h", "18h","20h", "22h", "24h")
    ) + 
  scale_y_continuous(trans = "log10",
    breaks = c(0,20,100,500,2500), 
    labels = c("0", "20", "100","500","2500"))
```

Conclusions: The old men seldom exercise on weekends and actively exercise with longer time from 8am-20pm during Weekdays. Monday is an exception that he active in the night.

## Problem 3

load data

```{r}
data("ny_noaa")
```

### Do some data cleaning

```{r}
 ny_noaa_tidy = ny_noaa %>% 
 separate(date, into = c("year", "month", "day"))
 ny_noaa_tidy = ny_noaa_tidy %>% 
  mutate_at(vars(year, month, day), as.factor) %>%  
  mutate_at(vars(tmax, tmin, prcp, snow, snwd), as.numeric) %>% 
  mutate(
    prcp = prcp / 10,
    tmax = tmax / 10,
    tmin = tmin / 10,
  )
 
```


```{r}
 snowfall = ny_noaa_tidy %>% 
  filter(snow != "NA") %>% 
 count(snow) %>% 
 arrange(desc(n))
```

The most commonly observed values is "0" because most of days are not snowy.

### plot of the average max temperature in January and July

```{r}
panel_plot = ny_noaa_tidy %>% 
 filter(month %in% c("01","07")) %>% 
 group_by(year, month, id) %>% 
  summarize(
    mean_tmax = mean(tmax)) %>% 
     drop_na() %>% 
 ggplot(aes(x = year, y = mean_tmax, color = id, group = id)) +
  geom_point(alpha = 0.5) + 
  theme_minimal() +
  theme(legend.position = "bottom") +
  theme(legend.position = 'none',
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(title = "plot of the average max temperature in January and July",
       x = "Year",
       y = "Temperature(C)",
       caption = "temperate date" )+
  facet_grid(~ month)
panel_plot
```

From 1981 to 1989 and 2003 to 2007, the average max temperature increases in January, while July.is much more steady In 1994 and 2003, temperature in January decrease widely. There are some outliners in January 1982, July 1988 and July 2004.

### Make a two-panel plot 

#### plot of tmax vs tmin for the full dataset 

```{r}
vs_plot = ny_noaa_tidy %>% 
 ggplot(aes(x = tmax, y = tmin)) + 
  geom_bin2d() +
   labs(title = "plot of tmax vs tmin for the full dataset ",
       x = "max temperature",
       y = "min temperature",
       caption = "temperate comparison")

vs_plot
```

#### a plot showing the distribution of snowfall values greater than 0 and less than 100 separately by year

```{r}
sn_plot = ny_noaa_tidy %>% 
 filter(snow>0, snow<100) %>% 
 ggplot(aes(x=year, y= snow, fill = year))+
 geom_violin(alpha= .5)+
  stat_summary(fun = "median", color = "blue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
 labs(title = "snowfall distribution(between 0 and 100) by year",
       x = "Year",
       y = "Snowfall(mm)")
 
sn_plot
```

Finally, marge two plots!

```{r}
vs_plot/sn_plot
```

The dataset has `r nrow(ny_noaa)` observations and `r ncol(ny_noaa)` variables, including `r names(ny_noaa)`.

Here is the proportion of missing values

```{r}
ny_noaa %>% 
  summarize(prcp_na = (sum(is.na(prcp)))/nrow(ny_noaa),
            snow_na = (sum(is.na(snow)))/nrow(ny_noaa),
            snwd_na = (sum(is.na(snwd)))/nrow(ny_noaa),
            tmax_na = (sum(is.na(tmax)))/nrow(ny_noaa),
            tmin_na = (sum(is.na(tmin)))/nrow(ny_noaa))
```

Almost half of maxium and minium temperature are missing, it is a big issue.
